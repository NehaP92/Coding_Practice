{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-05T21:38:02.376047Z","iopub.execute_input":"2021-07-05T21:38:02.376503Z","iopub.status.idle":"2021-07-05T21:38:02.388207Z","shell.execute_reply.started":"2021-07-05T21:38:02.376407Z","shell.execute_reply":"2021-07-05T21:38:02.387028Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Big Query","metadata":{}},{"cell_type":"code","source":"from google.cloud import bigquery","metadata":{"execution":{"iopub.status.busy":"2021-07-06T00:57:43.684855Z","iopub.execute_input":"2021-07-06T00:57:43.685334Z","iopub.status.idle":"2021-07-06T00:57:43.690169Z","shell.execute_reply.started":"2021-07-06T00:57:43.685289Z","shell.execute_reply":"2021-07-06T00:57:43.689231Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"client=bigquery.Client()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T00:57:44.610886Z","iopub.execute_input":"2021-07-06T00:57:44.611527Z","iopub.status.idle":"2021-07-06T00:57:44.618481Z","shell.execute_reply.started":"2021-07-06T00:57:44.611473Z","shell.execute_reply":"2021-07-06T00:57:44.617138Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Using Kaggle's public dataset BigQuery integration.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Construct a reference to the \"hacker_news\" dataset\ndataset_ref = client.dataset(\"hacker_news\", project=\"bigquery-public-data\")\n\n# API request - fetch the dataset\ndataset = client.get_dataset(dataset_ref)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T21:44:01.280919Z","iopub.execute_input":"2021-07-05T21:44:01.281347Z","iopub.status.idle":"2021-07-05T21:44:01.577540Z","shell.execute_reply.started":"2021-07-05T21:44:01.281314Z","shell.execute_reply":"2021-07-05T21:44:01.576716Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"tables = list(client.list_tables(dataset))","metadata":{"execution":{"iopub.status.busy":"2021-07-05T21:47:34.504128Z","iopub.execute_input":"2021-07-05T21:47:34.504533Z","iopub.status.idle":"2021-07-05T21:47:34.737898Z","shell.execute_reply.started":"2021-07-05T21:47:34.504498Z","shell.execute_reply":"2021-07-05T21:47:34.736989Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"for table in tables:\n    print(table.table_id)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T21:48:06.490169Z","iopub.execute_input":"2021-07-05T21:48:06.490527Z","iopub.status.idle":"2021-07-05T21:48:06.495480Z","shell.execute_reply.started":"2021-07-05T21:48:06.490499Z","shell.execute_reply":"2021-07-05T21:48:06.494730Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"comments\nfull\nfull_201510\nstories\n","output_type":"stream"}]},{"cell_type":"code","source":"table_ref = dataset_ref.table(\"full\")\ntable = client.get_table(table_ref)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T21:49:45.896815Z","iopub.execute_input":"2021-07-05T21:49:45.897414Z","iopub.status.idle":"2021-07-05T21:49:46.125310Z","shell.execute_reply.started":"2021-07-05T21:49:45.897367Z","shell.execute_reply":"2021-07-05T21:49:46.124412Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"table.description","metadata":{"execution":{"iopub.status.busy":"2021-07-05T21:50:58.615011Z","iopub.execute_input":"2021-07-05T21:50:58.615440Z","iopub.status.idle":"2021-07-05T21:50:58.620419Z","shell.execute_reply.started":"2021-07-05T21:50:58.615405Z","shell.execute_reply":"2021-07-05T21:50:58.619450Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"'A full daily update of all the stories and comments in Hacker News.'"},"metadata":{}}]},{"cell_type":"code","source":"table.num_rows","metadata":{"execution":{"iopub.status.busy":"2021-07-05T21:51:09.414656Z","iopub.execute_input":"2021-07-05T21:51:09.415161Z","iopub.status.idle":"2021-07-05T21:51:09.419989Z","shell.execute_reply.started":"2021-07-05T21:51:09.415127Z","shell.execute_reply":"2021-07-05T21:51:09.419085Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"27708712"},"metadata":{}}]},{"cell_type":"markdown","source":"## Table Schema","metadata":{}},{"cell_type":"code","source":"table.schema","metadata":{"execution":{"iopub.status.busy":"2021-07-05T21:59:23.252361Z","iopub.execute_input":"2021-07-05T21:59:23.252731Z","iopub.status.idle":"2021-07-05T21:59:23.259264Z","shell.execute_reply.started":"2021-07-05T21:59:23.252704Z","shell.execute_reply":"2021-07-05T21:59:23.258199Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"[SchemaField('title', 'STRING', 'NULLABLE', 'Story title', (), None),\n SchemaField('url', 'STRING', 'NULLABLE', 'Story url', (), None),\n SchemaField('text', 'STRING', 'NULLABLE', 'Story or comment text', (), None),\n SchemaField('dead', 'BOOLEAN', 'NULLABLE', 'Is dead?', (), None),\n SchemaField('by', 'STRING', 'NULLABLE', \"The username of the item's author.\", (), None),\n SchemaField('score', 'INTEGER', 'NULLABLE', 'Story score', (), None),\n SchemaField('time', 'INTEGER', 'NULLABLE', 'Unix time', (), None),\n SchemaField('timestamp', 'TIMESTAMP', 'NULLABLE', 'Timestamp for the unix time', (), None),\n SchemaField('type', 'STRING', 'NULLABLE', 'Type of details (comment, comment_ranking, poll, story, job, pollopt)', (), None),\n SchemaField('id', 'INTEGER', 'NULLABLE', \"The item's unique id.\", (), None),\n SchemaField('parent', 'INTEGER', 'NULLABLE', 'Parent comment ID', (), None),\n SchemaField('descendants', 'INTEGER', 'NULLABLE', 'Number of story or poll descendants', (), None),\n SchemaField('ranking', 'INTEGER', 'NULLABLE', 'Comment ranking', (), None),\n SchemaField('deleted', 'BOOLEAN', 'NULLABLE', 'Is deleted?', (), None)]"},"metadata":{}}]},{"cell_type":"code","source":"client.list_rows(table,max_results=5)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T22:15:05.857510Z","iopub.execute_input":"2021-07-05T22:15:05.857902Z","iopub.status.idle":"2021-07-05T22:15:05.864134Z","shell.execute_reply.started":"2021-07-05T22:15:05.857871Z","shell.execute_reply":"2021-07-05T22:15:05.863208Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"<google.cloud.bigquery.table.RowIterator at 0x7f31cbbd6750>"},"metadata":{}}]},{"cell_type":"code","source":"client.list_rows(table,max_results=5).to_dataframe()","metadata":{"execution":{"iopub.status.busy":"2021-07-05T22:15:26.866707Z","iopub.execute_input":"2021-07-05T22:15:26.867133Z","iopub.status.idle":"2021-07-05T22:15:27.470210Z","shell.execute_reply.started":"2021-07-05T22:15:26.867085Z","shell.execute_reply":"2021-07-05T22:15:27.469421Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Cannot use bqstorage_client if max_results is set, reverting to fetching data with the tabledata.list endpoint.\n  \"\"\"Entry point for launching an IPython kernel.\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"  title   url                                               text  dead  \\\n0  None  None  &gt;I&#x27;m done with this conversation since...  None   \n1  None  None  What do you mean by sync being hard to impleme...  None   \n2  None  None  This is pretty dumb and naive, and loaded with...  None   \n3  None  None  5. Biker not using lights at night &quot;becau...  None   \n4  None  None  But they are all either very inexpensive or th...  None   \n\n         by  score        time                 timestamp     type        id  \\\n0    noobly    NaN  1541023247 2018-10-31 22:00:47+00:00  comment  18349611   \n1  e_proxus    NaN  1434378064 2015-06-15 14:21:04+00:00  comment   9719409   \n2     Retra    NaN  1434378063 2015-06-15 14:21:03+00:00  comment   9719408   \n3      rjsw    NaN  1434378022 2015-06-15 14:20:22+00:00  comment   9719401   \n4  g8gggu89    NaN  1434378020 2015-06-15 14:20:20+00:00  comment   9719400   \n\n     parent  descendants  ranking deleted  \n0  18348253          NaN      NaN    None  \n1   9719293          NaN      NaN    None  \n2   9719205          NaN      NaN    None  \n3   9719372          NaN      NaN    None  \n4   9719006          NaN      NaN    None  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>url</th>\n      <th>text</th>\n      <th>dead</th>\n      <th>by</th>\n      <th>score</th>\n      <th>time</th>\n      <th>timestamp</th>\n      <th>type</th>\n      <th>id</th>\n      <th>parent</th>\n      <th>descendants</th>\n      <th>ranking</th>\n      <th>deleted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>None</td>\n      <td>None</td>\n      <td>&amp;gt;I&amp;#x27;m done with this conversation since...</td>\n      <td>None</td>\n      <td>noobly</td>\n      <td>NaN</td>\n      <td>1541023247</td>\n      <td>2018-10-31 22:00:47+00:00</td>\n      <td>comment</td>\n      <td>18349611</td>\n      <td>18348253</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>None</td>\n      <td>None</td>\n      <td>What do you mean by sync being hard to impleme...</td>\n      <td>None</td>\n      <td>e_proxus</td>\n      <td>NaN</td>\n      <td>1434378064</td>\n      <td>2015-06-15 14:21:04+00:00</td>\n      <td>comment</td>\n      <td>9719409</td>\n      <td>9719293</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>None</td>\n      <td>None</td>\n      <td>This is pretty dumb and naive, and loaded with...</td>\n      <td>None</td>\n      <td>Retra</td>\n      <td>NaN</td>\n      <td>1434378063</td>\n      <td>2015-06-15 14:21:03+00:00</td>\n      <td>comment</td>\n      <td>9719408</td>\n      <td>9719205</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>None</td>\n      <td>None</td>\n      <td>5. Biker not using lights at night &amp;quot;becau...</td>\n      <td>None</td>\n      <td>rjsw</td>\n      <td>NaN</td>\n      <td>1434378022</td>\n      <td>2015-06-15 14:20:22+00:00</td>\n      <td>comment</td>\n      <td>9719401</td>\n      <td>9719372</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>None</td>\n      <td>None</td>\n      <td>But they are all either very inexpensive or th...</td>\n      <td>None</td>\n      <td>g8gggu89</td>\n      <td>NaN</td>\n      <td>1434378020</td>\n      <td>2015-06-15 14:20:20+00:00</td>\n      <td>comment</td>\n      <td>9719400</td>\n      <td>9719006</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"client.list_rows(table, selected_fields=table.schema[:1], max_results = 5).to_dataframe()","metadata":{"execution":{"iopub.status.busy":"2021-07-05T22:18:55.709240Z","iopub.execute_input":"2021-07-05T22:18:55.709844Z","iopub.status.idle":"2021-07-05T22:18:56.107057Z","shell.execute_reply.started":"2021-07-05T22:18:55.709809Z","shell.execute_reply":"2021-07-05T22:18:56.106139Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Cannot use bqstorage_client if max_results is set, reverting to fetching data with the tabledata.list endpoint.\n  \"\"\"Entry point for launching an IPython kernel.\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"  title\n0  None\n1  None\n2  None\n3  None\n4  None","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Select, From and Where in Bigquery","metadata":{}},{"cell_type":"code","source":"dataset_ref=(client.dataset(\"openaq\", project = \"bigquery-public-data\"))\ndataset=client.get_dataset(dataset_ref)\n\ntables = list(client.list_tables(dataset))\nfor table in tables:\n    print(table.table_id)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T00:58:15.699639Z","iopub.execute_input":"2021-07-06T00:58:15.700021Z","iopub.status.idle":"2021-07-06T00:58:16.180144Z","shell.execute_reply.started":"2021-07-06T00:58:15.699989Z","shell.execute_reply":"2021-07-06T00:58:16.179356Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"global_air_quality\n","output_type":"stream"}]},{"cell_type":"code","source":"table_ref = dataset_ref.table(\"global_air_quality\")\ntable = client.get_table(table_ref)\n\nclient.list_rows(table, max_results=5).to_dataframe()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T00:58:19.145021Z","iopub.execute_input":"2021-07-06T00:58:19.145443Z","iopub.status.idle":"2021-07-06T00:58:19.987553Z","shell.execute_reply.started":"2021-07-06T00:58:19.145411Z","shell.execute_reply":"2021-07-06T00:58:19.986693Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: Cannot use bqstorage_client if max_results is set, reverting to fetching data with the tabledata.list endpoint.\n  after removing the cwd from sys.path.\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                        location       city country pollutant   value  \\\n0  BTM Layout, Bengaluru - KSPCB  Bengaluru      IN        co  910.00   \n1  BTM Layout, Bengaluru - KSPCB  Bengaluru      IN       no2  131.87   \n2  BTM Layout, Bengaluru - KSPCB  Bengaluru      IN        o3   15.57   \n3  BTM Layout, Bengaluru - KSPCB  Bengaluru      IN      pm25   45.62   \n4  BTM Layout, Bengaluru - KSPCB  Bengaluru      IN       so2    4.49   \n\n                  timestamp   unit source_name   latitude  longitude  \\\n0 2018-02-22 03:00:00+00:00  µg/m³        CPCB  12.912811   77.60922   \n1 2018-02-22 03:00:00+00:00  µg/m³        CPCB  12.912811   77.60922   \n2 2018-02-22 03:00:00+00:00  µg/m³        CPCB  12.912811   77.60922   \n3 2018-02-22 03:00:00+00:00  µg/m³        CPCB  12.912811   77.60922   \n4 2018-02-22 03:00:00+00:00  µg/m³        CPCB  12.912811   77.60922   \n\n   averaged_over_in_hours  \n0                    0.25  \n1                    0.25  \n2                    0.25  \n3                    0.25  \n4                    0.25  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>location</th>\n      <th>city</th>\n      <th>country</th>\n      <th>pollutant</th>\n      <th>value</th>\n      <th>timestamp</th>\n      <th>unit</th>\n      <th>source_name</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>averaged_over_in_hours</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>BTM Layout, Bengaluru - KSPCB</td>\n      <td>Bengaluru</td>\n      <td>IN</td>\n      <td>co</td>\n      <td>910.00</td>\n      <td>2018-02-22 03:00:00+00:00</td>\n      <td>µg/m³</td>\n      <td>CPCB</td>\n      <td>12.912811</td>\n      <td>77.60922</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>BTM Layout, Bengaluru - KSPCB</td>\n      <td>Bengaluru</td>\n      <td>IN</td>\n      <td>no2</td>\n      <td>131.87</td>\n      <td>2018-02-22 03:00:00+00:00</td>\n      <td>µg/m³</td>\n      <td>CPCB</td>\n      <td>12.912811</td>\n      <td>77.60922</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>BTM Layout, Bengaluru - KSPCB</td>\n      <td>Bengaluru</td>\n      <td>IN</td>\n      <td>o3</td>\n      <td>15.57</td>\n      <td>2018-02-22 03:00:00+00:00</td>\n      <td>µg/m³</td>\n      <td>CPCB</td>\n      <td>12.912811</td>\n      <td>77.60922</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>BTM Layout, Bengaluru - KSPCB</td>\n      <td>Bengaluru</td>\n      <td>IN</td>\n      <td>pm25</td>\n      <td>45.62</td>\n      <td>2018-02-22 03:00:00+00:00</td>\n      <td>µg/m³</td>\n      <td>CPCB</td>\n      <td>12.912811</td>\n      <td>77.60922</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>BTM Layout, Bengaluru - KSPCB</td>\n      <td>Bengaluru</td>\n      <td>IN</td>\n      <td>so2</td>\n      <td>4.49</td>\n      <td>2018-02-22 03:00:00+00:00</td>\n      <td>µg/m³</td>\n      <td>CPCB</td>\n      <td>12.912811</td>\n      <td>77.60922</td>\n      <td>0.25</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"query=\"\"\"SELECT city\n         FROM `bigquery-public-data.openaq.global_air_quality`\n         WHERE country = 'US'\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-07-05T22:53:29.357308Z","iopub.execute_input":"2021-07-05T22:53:29.357722Z","iopub.status.idle":"2021-07-05T22:53:29.361658Z","shell.execute_reply.started":"2021-07-05T22:53:29.357676Z","shell.execute_reply":"2021-07-05T22:53:29.360823Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"client=bigquery.Client()\nquery_job = client.query(query)\n\nus_cities = query_job.to_dataframe()\n\nus_cities","metadata":{"execution":{"iopub.status.busy":"2021-07-05T22:55:18.641815Z","iopub.execute_input":"2021-07-05T22:55:18.642195Z","iopub.status.idle":"2021-07-05T22:55:19.646474Z","shell.execute_reply.started":"2021-07-05T22:55:18.642161Z","shell.execute_reply":"2021-07-05T22:55:19.645532Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Using Kaggle's public dataset BigQuery integration.\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/google/cloud/bigquery/client.py:440: UserWarning: Cannot create BigQuery Storage client, the dependency google-cloud-bigquery-storage is not installed.\n  \"Cannot create BigQuery Storage client, the dependency \"\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"                 city\n0               BROWN\n1               BROWN\n2               BROWN\n3               BROWN\n4             Houston\n...               ...\n3718          Atlanta\n3719  Mammoth Cave NP\n3720       Las Cruces\n3721           MARTIN\n3722           Moscow\n\n[3723 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>city</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>BROWN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>BROWN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>BROWN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>BROWN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Houston</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3718</th>\n      <td>Atlanta</td>\n    </tr>\n    <tr>\n      <th>3719</th>\n      <td>Mammoth Cave NP</td>\n    </tr>\n    <tr>\n      <th>3720</th>\n      <td>Las Cruces</td>\n    </tr>\n    <tr>\n      <th>3721</th>\n      <td>MARTIN</td>\n    </tr>\n    <tr>\n      <th>3722</th>\n      <td>Moscow</td>\n    </tr>\n  </tbody>\n</table>\n<p>3723 rows × 1 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"us_cities.city.value_counts().head()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T00:57:31.253272Z","iopub.execute_input":"2021-07-06T00:57:31.253763Z","iopub.status.idle":"2021-07-06T00:57:31.331367Z","shell.execute_reply.started":"2021-07-06T00:57:31.253661Z","shell.execute_reply":"2021-07-06T00:57:31.330261Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-7fd6cef98bbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mus_cities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'us_cities' is not defined"],"ename":"NameError","evalue":"name 'us_cities' is not defined","output_type":"error"}]},{"cell_type":"markdown","source":"Since there is a limit of 5TB, you can first calculate the size of the query:","metadata":{}},{"cell_type":"code","source":"query=\"\"\"SELECT city,country\n         FROM `bigquery-public-data.openaq.global_air_quality`\n         WHERE country = 'US'\"\"\"\n\ndry_run_config = bigquery.QueryJobConfig(dry_run = True)\n\ndry_run_query_job=client.query(query,job_config = dry_run_config)\n\nprint(f'This query will process {dry_run_query_job.total_bytes_processed} bytes')","metadata":{"execution":{"iopub.status.busy":"2021-07-06T01:03:20.434169Z","iopub.execute_input":"2021-07-06T01:03:20.434593Z","iopub.status.idle":"2021-07-06T01:03:20.796611Z","shell.execute_reply.started":"2021-07-06T01:03:20.434558Z","shell.execute_reply":"2021-07-06T01:03:20.795083Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"This query will process 362151 bytes\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f'This query will process {(dry_run_query_job.total_bytes_processed)/1000000} mb')","metadata":{"execution":{"iopub.status.busy":"2021-07-06T01:04:47.607556Z","iopub.execute_input":"2021-07-06T01:04:47.607963Z","iopub.status.idle":"2021-07-06T01:04:47.614658Z","shell.execute_reply.started":"2021-07-06T01:04:47.607930Z","shell.execute_reply":"2021-07-06T01:04:47.613262Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"This query will process 0.362151 mb\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f'This query will process {(dry_run_query_job.total_bytes_processed)/1000000000} gb')","metadata":{"execution":{"iopub.status.busy":"2021-07-06T01:07:06.008559Z","iopub.execute_input":"2021-07-06T01:07:06.009377Z","iopub.status.idle":"2021-07-06T01:07:06.017159Z","shell.execute_reply.started":"2021-07-06T01:07:06.009330Z","shell.execute_reply":"2021-07-06T01:07:06.015442Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"This query will process 0.000362151 gb\n","output_type":"stream"}]},{"cell_type":"markdown","source":"You can also specify a parameter when running the query to limit how much data you are willing to scan. Here's an example with a low limit.","metadata":{}},{"cell_type":"code","source":"# Only run the query if it's less than 1 MB\nONE_MB = 1000*1000\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=ONE_MB)\n\n# Set up the query (will only run if it's less than 1 MB)\nsafe_query_job = client.query(query, job_config=safe_config)\n\n# API request - try to run the query, and return a pandas DataFrame\nsafe_query_job.to_dataframe()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T01:13:45.651579Z","iopub.execute_input":"2021-07-06T01:13:45.652029Z","iopub.status.idle":"2021-07-06T01:13:46.120352Z","shell.execute_reply.started":"2021-07-06T01:13:45.651995Z","shell.execute_reply":"2021-07-06T01:13:46.118017Z"},"trusted":true},"execution_count":15,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInternalServerError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-3ffb41147547>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# API request - try to run the query, and return a pandas DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0msafe_query_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/bigquery/job.py\u001b[0m in \u001b[0;36mto_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, date_as_object)\u001b[0m\n\u001b[1;32m   3403\u001b[0m             \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mpandas\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mlibrary\u001b[0m \u001b[0mcannot\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mimported\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3404\u001b[0m         \"\"\"\n\u001b[0;32m-> 3405\u001b[0;31m         return self.result().to_dataframe(\n\u001b[0m\u001b[1;32m   3406\u001b[0m             \u001b[0mbqstorage_client\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbqstorage_client\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3407\u001b[0m             \u001b[0mdtypes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/bigquery/job.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, page_size, max_results, retry, timeout, start_index)\u001b[0m\n\u001b[1;32m   3232\u001b[0m         \"\"\"\n\u001b[1;32m   3233\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3234\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQueryJob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3236\u001b[0m             \u001b[0;31m# Return an iterator instead of returning the job.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/bigquery/job.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, retry, timeout)\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0;31m# TODO: modify PollingFuture so it can pass a retry argument to done().\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_AsyncJob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcancelled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/api_core/future/polling.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout, retry)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;31m# pylint: disable=raising-bad-type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;31m# Pylint doesn't recognize that this is valid in this case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInternalServerError\u001b[0m: 500 Query exceeded limit for bytes billed: 1000000. 10485760 or higher required.\n\n(job ID: cebbf7f8-c5f4-48d5-a181-989344505592)\n\n                  -----Query Job SQL Follows-----                  \n\n    |    .    |    .    |    .    |    .    |    .    |    .    |\n   1:SELECT city,country\n   2:         FROM `bigquery-public-data.openaq.global_air_quality`\n   3:         WHERE country = 'US'\n    |    .    |    .    |    .    |    .    |    .    |    .    |"],"ename":"InternalServerError","evalue":"500 Query exceeded limit for bytes billed: 1000000. 10485760 or higher required.\n\n(job ID: cebbf7f8-c5f4-48d5-a181-989344505592)\n\n                  -----Query Job SQL Follows-----                  \n\n    |    .    |    .    |    .    |    .    |    .    |    .    |\n   1:SELECT city,country\n   2:         FROM `bigquery-public-data.openaq.global_air_quality`\n   3:         WHERE country = 'US'\n    |    .    |    .    |    .    |    .    |    .    |    .    |","output_type":"error"}]},{"cell_type":"code","source":"# Only run the query if it's less than 1 MB\nONE_MB = 1000*1000\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=100000000)\n\n# Set up the query (will only run if it's less than 1 MB)\nsafe_query_job = client.query(query, job_config=safe_config)\n\n# API request - try to run the query, and return a pandas DataFrame\nsafe_query_job.to_dataframe()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T01:14:13.667431Z","iopub.execute_input":"2021-07-06T01:14:13.667842Z","iopub.status.idle":"2021-07-06T01:14:14.864743Z","shell.execute_reply.started":"2021-07-06T01:14:13.667809Z","shell.execute_reply":"2021-07-06T01:14:14.863686Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/google/cloud/bigquery/client.py:440: UserWarning: Cannot create BigQuery Storage client, the dependency google-cloud-bigquery-storage is not installed.\n  \"Cannot create BigQuery Storage client, the dependency \"\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"                 city country\n0               BROWN      US\n1               BROWN      US\n2               BROWN      US\n3               BROWN      US\n4             Houston      US\n...               ...     ...\n3718          Atlanta      US\n3719  Mammoth Cave NP      US\n3720       Las Cruces      US\n3721           MARTIN      US\n3722           Moscow      US\n\n[3723 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>city</th>\n      <th>country</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>BROWN</td>\n      <td>US</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>BROWN</td>\n      <td>US</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>BROWN</td>\n      <td>US</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>BROWN</td>\n      <td>US</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Houston</td>\n      <td>US</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3718</th>\n      <td>Atlanta</td>\n      <td>US</td>\n    </tr>\n    <tr>\n      <th>3719</th>\n      <td>Mammoth Cave NP</td>\n      <td>US</td>\n    </tr>\n    <tr>\n      <th>3720</th>\n      <td>Las Cruces</td>\n      <td>US</td>\n    </tr>\n    <tr>\n      <th>3721</th>\n      <td>MARTIN</td>\n      <td>US</td>\n    </tr>\n    <tr>\n      <th>3722</th>\n      <td>Moscow</td>\n      <td>US</td>\n    </tr>\n  </tbody>\n</table>\n<p>3723 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"The query gets cancelled if the limit of 1 MB exceeds. However, we can increase the limit to run the query successfully!","metadata":{}},{"cell_type":"code","source":"# Only run the query if it's less than 1 GB\nONE_GB = 1000*1000*1000\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=ONE_GB)\n\n# Set up the query (will only run if it's less than 1 GB)\nsafe_query_job = client.query(query, job_config=safe_config)\n\n# API request - try to run the query, and return a pandas DataFrame\njob_post_scores = safe_query_job.to_dataframe()\n\n# Print average score for job posts\njob_post_scores.score.mean()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T01:17:55.073967Z","iopub.execute_input":"2021-07-06T01:17:55.074430Z","iopub.status.idle":"2021-07-06T01:17:56.092496Z","shell.execute_reply.started":"2021-07-06T01:17:55.074394Z","shell.execute_reply":"2021-07-06T01:17:56.090436Z"},"trusted":true},"execution_count":20,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-c2386059a6b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Print average score for job posts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mjob_post_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5463\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5464\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5465\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5467\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'score'"],"ename":"AttributeError","evalue":"'DataFrame' object has no attribute 'score'","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}