{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-10T19:21:48.746753Z","iopub.execute_input":"2021-07-10T19:21:48.747318Z","iopub.status.idle":"2021-07-10T19:21:48.760294Z","shell.execute_reply.started":"2021-07-10T19:21:48.747176Z","shell.execute_reply":"2021-07-10T19:21:48.759386Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Big Query","metadata":{}},{"cell_type":"code","source":"from google.cloud import bigquery","metadata":{"execution":{"iopub.status.busy":"2021-07-10T19:21:55.558108Z","iopub.execute_input":"2021-07-10T19:21:55.558783Z","iopub.status.idle":"2021-07-10T19:21:55.563822Z","shell.execute_reply.started":"2021-07-10T19:21:55.558743Z","shell.execute_reply":"2021-07-10T19:21:55.562257Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"client=bigquery.Client()","metadata":{"execution":{"iopub.status.busy":"2021-07-10T19:21:56.444153Z","iopub.execute_input":"2021-07-10T19:21:56.444552Z","iopub.status.idle":"2021-07-10T19:21:56.451138Z","shell.execute_reply.started":"2021-07-10T19:21:56.444520Z","shell.execute_reply":"2021-07-10T19:21:56.450208Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Using Kaggle's public dataset BigQuery integration.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Construct a reference to the \"hacker_news\" dataset\ndataset_ref = client.dataset(\"hacker_news\", project=\"bigquery-public-data\")\n\n# API request - fetch the dataset\ndataset = client.get_dataset(dataset_ref)","metadata":{"execution":{"iopub.status.busy":"2021-07-07T03:39:57.888411Z","iopub.execute_input":"2021-07-07T03:39:57.888758Z","iopub.status.idle":"2021-07-07T03:39:58.142023Z","shell.execute_reply.started":"2021-07-07T03:39:57.888726Z","shell.execute_reply":"2021-07-07T03:39:58.141076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tables = list(client.list_tables(dataset))","metadata":{"execution":{"iopub.status.busy":"2021-07-07T03:40:02.461287Z","iopub.execute_input":"2021-07-07T03:40:02.461674Z","iopub.status.idle":"2021-07-07T03:40:02.646266Z","shell.execute_reply.started":"2021-07-07T03:40:02.461643Z","shell.execute_reply":"2021-07-07T03:40:02.645403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for table in tables:\n    print(table.table_id)","metadata":{"execution":{"iopub.status.busy":"2021-07-07T03:40:03.493958Z","iopub.execute_input":"2021-07-07T03:40:03.494342Z","iopub.status.idle":"2021-07-07T03:40:03.500043Z","shell.execute_reply.started":"2021-07-07T03:40:03.494313Z","shell.execute_reply":"2021-07-07T03:40:03.498962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"table_ref = dataset_ref.table(\"full\")\ntable = client.get_table(table_ref)","metadata":{"execution":{"iopub.status.busy":"2021-07-07T03:48:29.821225Z","iopub.execute_input":"2021-07-07T03:48:29.821615Z","iopub.status.idle":"2021-07-07T03:48:30.010475Z","shell.execute_reply.started":"2021-07-07T03:48:29.82157Z","shell.execute_reply":"2021-07-07T03:48:30.009727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"table.description","metadata":{"execution":{"iopub.status.busy":"2021-07-07T03:48:30.961385Z","iopub.execute_input":"2021-07-07T03:48:30.961746Z","iopub.status.idle":"2021-07-07T03:48:30.970137Z","shell.execute_reply.started":"2021-07-07T03:48:30.961705Z","shell.execute_reply":"2021-07-07T03:48:30.968752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"table.num_rows","metadata":{"execution":{"iopub.status.busy":"2021-07-07T03:48:34.455719Z","iopub.execute_input":"2021-07-07T03:48:34.456113Z","iopub.status.idle":"2021-07-07T03:48:34.46225Z","shell.execute_reply.started":"2021-07-07T03:48:34.456075Z","shell.execute_reply":"2021-07-07T03:48:34.461252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Table Schema","metadata":{}},{"cell_type":"code","source":"table.schema","metadata":{"execution":{"iopub.status.busy":"2021-07-07T03:50:35.731289Z","iopub.execute_input":"2021-07-07T03:50:35.731673Z","iopub.status.idle":"2021-07-07T03:50:35.737059Z","shell.execute_reply.started":"2021-07-07T03:50:35.731642Z","shell.execute_reply":"2021-07-07T03:50:35.736319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"client.list_rows(table,max_results=5)","metadata":{"execution":{"iopub.status.busy":"2021-07-07T03:52:21.464334Z","iopub.execute_input":"2021-07-07T03:52:21.464976Z","iopub.status.idle":"2021-07-07T03:52:21.470286Z","shell.execute_reply.started":"2021-07-07T03:52:21.46494Z","shell.execute_reply":"2021-07-07T03:52:21.469583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"client.list_rows(table,max_results=5).to_dataframe()","metadata":{"execution":{"iopub.status.busy":"2021-07-07T03:53:34.863162Z","iopub.execute_input":"2021-07-07T03:53:34.863607Z","iopub.status.idle":"2021-07-07T03:53:35.849791Z","shell.execute_reply.started":"2021-07-07T03:53:34.863559Z","shell.execute_reply":"2021-07-07T03:53:35.848646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"client.list_rows(table, selected_fields=table.schema[:1], max_results = 5).to_dataframe()","metadata":{"execution":{"iopub.status.busy":"2021-07-07T03:54:20.157487Z","iopub.execute_input":"2021-07-07T03:54:20.15786Z","iopub.status.idle":"2021-07-07T03:54:20.383984Z","shell.execute_reply.started":"2021-07-07T03:54:20.157829Z","shell.execute_reply":"2021-07-07T03:54:20.382933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Select, From and Where in Bigquery","metadata":{}},{"cell_type":"code","source":"dataset_ref=(client.dataset(\"openaq\", project = \"bigquery-public-data\"))\ndataset=client.get_dataset(dataset_ref)\n\ntables = list(client.list_tables(dataset))\nfor table in tables:\n    print(table.table_id)","metadata":{"execution":{"iopub.status.busy":"2021-07-07T03:59:37.069275Z","iopub.execute_input":"2021-07-07T03:59:37.069649Z","iopub.status.idle":"2021-07-07T03:59:37.380933Z","shell.execute_reply.started":"2021-07-07T03:59:37.069618Z","shell.execute_reply":"2021-07-07T03:59:37.379857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"table_ref = dataset_ref.table(\"global_air_quality\")\ntable = client.get_table(table_ref)\n\nclient.list_rows(table, max_results=5).to_dataframe()","metadata":{"execution":{"iopub.status.busy":"2021-07-07T03:59:40.856591Z","iopub.execute_input":"2021-07-07T03:59:40.857005Z","iopub.status.idle":"2021-07-07T03:59:41.231463Z","shell.execute_reply.started":"2021-07-07T03:59:40.856968Z","shell.execute_reply":"2021-07-07T03:59:41.23078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"query=\"\"\"SELECT city\n         FROM `bigquery-public-data.openaq.global_air_quality`\n         WHERE country = 'US'\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-07-07T04:00:34.847449Z","iopub.execute_input":"2021-07-07T04:00:34.847999Z","iopub.status.idle":"2021-07-07T04:00:34.852444Z","shell.execute_reply.started":"2021-07-07T04:00:34.847962Z","shell.execute_reply":"2021-07-07T04:00:34.851657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"client=bigquery.Client()\nquery_job = client.query(query)\n\nus_cities = query_job.to_dataframe()\n\nus_cities","metadata":{"execution":{"iopub.status.busy":"2021-07-07T04:00:46.218007Z","iopub.execute_input":"2021-07-07T04:00:46.218633Z","iopub.status.idle":"2021-07-07T04:00:47.029579Z","shell.execute_reply.started":"2021-07-07T04:00:46.218582Z","shell.execute_reply":"2021-07-07T04:00:47.028868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"us_cities.city.value_counts().head()","metadata":{"execution":{"iopub.status.busy":"2021-07-07T04:02:53.092429Z","iopub.execute_input":"2021-07-07T04:02:53.092952Z","iopub.status.idle":"2021-07-07T04:02:53.103926Z","shell.execute_reply.started":"2021-07-07T04:02:53.09292Z","shell.execute_reply":"2021-07-07T04:02:53.102908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since there is a limit of 5TB, you can first calculate the size of the query:","metadata":{}},{"cell_type":"code","source":"query=\"\"\"SELECT city,country\n         FROM `bigquery-public-data.openaq.global_air_quality`\n         WHERE country = 'US'\"\"\"\n\ndry_run_config = bigquery.QueryJobConfig(dry_run = True)\n\ndry_run_query_job=client.query(query,job_config = dry_run_config)\n\nprint(f'This query will process {dry_run_query_job.total_bytes_processed} bytes')","metadata":{"execution":{"iopub.status.busy":"2021-07-07T04:06:11.96464Z","iopub.execute_input":"2021-07-07T04:06:11.96498Z","iopub.status.idle":"2021-07-07T04:06:12.222806Z","shell.execute_reply.started":"2021-07-07T04:06:11.964953Z","shell.execute_reply":"2021-07-07T04:06:12.221796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'This query will process {(dry_run_query_job.total_bytes_processed)/1000000} mb')","metadata":{"execution":{"iopub.status.busy":"2021-07-07T04:06:35.841125Z","iopub.execute_input":"2021-07-07T04:06:35.841457Z","iopub.status.idle":"2021-07-07T04:06:35.846165Z","shell.execute_reply.started":"2021-07-07T04:06:35.841428Z","shell.execute_reply":"2021-07-07T04:06:35.845367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'This query will process {(dry_run_query_job.total_bytes_processed)/1000000000} gb')","metadata":{"execution":{"iopub.status.busy":"2021-07-06T01:07:06.008559Z","iopub.execute_input":"2021-07-06T01:07:06.009377Z","iopub.status.idle":"2021-07-06T01:07:06.017159Z","shell.execute_reply.started":"2021-07-06T01:07:06.00933Z","shell.execute_reply":"2021-07-06T01:07:06.015442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You can also specify a parameter when running the query to limit how much data you are willing to scan. Here's an example with a low limit.","metadata":{}},{"cell_type":"code","source":"# Only run the query if it's less than 1 MB\nONE_MB = 1000*1000\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=ONE_MB)\n\n# Set up the query (will only run if it's less than 1 MB)\nsafe_query_job = client.query(query, job_config=safe_config)\n\n# API request - try to run the query, and return a pandas DataFrame\nsafe_query_job.to_dataframe()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T01:13:45.651579Z","iopub.execute_input":"2021-07-06T01:13:45.652029Z","iopub.status.idle":"2021-07-06T01:13:46.120352Z","shell.execute_reply.started":"2021-07-06T01:13:45.651995Z","shell.execute_reply":"2021-07-06T01:13:46.118017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Only run the query if it's less than 1 MB\nONE_MB = 1000*1000\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=100000000)\n\n# Set up the query (will only run if it's less than 1 MB)\nsafe_query_job = client.query(query, job_config=safe_config)\n\n# API request - try to run the query, and return a pandas DataFrame\nsafe_query_job.to_dataframe()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T01:14:13.667431Z","iopub.execute_input":"2021-07-06T01:14:13.667842Z","iopub.status.idle":"2021-07-06T01:14:14.864743Z","shell.execute_reply.started":"2021-07-06T01:14:13.667809Z","shell.execute_reply":"2021-07-06T01:14:14.863686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The query gets cancelled if the limit of 1 MB exceeds. However, we can increase the limit to run the query successfully!","metadata":{}},{"cell_type":"code","source":"# Only run the query if it's less than 1 GB\nONE_GB = 1000*1000*1000\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=ONE_GB)\n\n# Set up the query (will only run if it's less than 1 GB)\nsafe_query_job = client.query(query, job_config=safe_config)\n\n# API request - try to run the query, and return a pandas DataFrame\njob_post_scores = safe_query_job.to_dataframe()\n\n# Print average score for job posts\njob_post_scores.score.mean()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T01:17:55.073967Z","iopub.execute_input":"2021-07-06T01:17:55.07443Z","iopub.status.idle":"2021-07-06T01:17:56.092496Z","shell.execute_reply.started":"2021-07-06T01:17:55.074394Z","shell.execute_reply":"2021-07-06T01:17:56.090436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## GroupBy, Having and Count","metadata":{}},{"cell_type":"code","source":"dataset_ref = client.dataset(\"hacker_news\", project = \"bigquery-public-data\")\ndataset = client.get_dataset(dataset_ref)\n\ntable_ref = dataset_ref.table(\"comments\")\ntable = client.get_table(table_ref)\n\nclient.list_rows(table, max_results = 5).to_dataframe()","metadata":{"execution":{"iopub.status.busy":"2021-07-10T19:22:02.285046Z","iopub.execute_input":"2021-07-10T19:22:02.287529Z","iopub.status.idle":"2021-07-10T19:22:03.299597Z","shell.execute_reply.started":"2021-07-10T19:22:02.287474Z","shell.execute_reply":"2021-07-10T19:22:03.297547Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: Cannot use bqstorage_client if max_results is set, reverting to fetching data with the tabledata.list endpoint.\n  import sys\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"         id  by author        time                   time_ts  \\\n0   2701393  5l     5l  1309184881 2011-06-27 14:28:01+00:00   \n1   5811403  99     99  1370234048 2013-06-03 04:34:08+00:00   \n2     21623  AF     AF  1178992400 2007-05-12 17:53:20+00:00   \n3  10159727  EA     EA  1441206574 2015-09-02 15:09:34+00:00   \n4   2988424  Iv     Iv  1315853580 2011-09-12 18:53:00+00:00   \n\n                                                text    parent deleted  dead  \\\n0  And the glazier who fixed all the broken windo...   2701243    None  None   \n1  Does canada have the equivalent of H1B/Green c...   5804452    None  None   \n2  Speaking of Rails, there are other options in ...     21611    None  None   \n3  Humans and large livestock (and maybe even pet...  10159396    None  None   \n4  I must say I reacted in the same way when I re...   2988179    None  None   \n\n   ranking  \n0        0  \n1        0  \n2        0  \n3        0  \n4        0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>by</th>\n      <th>author</th>\n      <th>time</th>\n      <th>time_ts</th>\n      <th>text</th>\n      <th>parent</th>\n      <th>deleted</th>\n      <th>dead</th>\n      <th>ranking</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2701393</td>\n      <td>5l</td>\n      <td>5l</td>\n      <td>1309184881</td>\n      <td>2011-06-27 14:28:01+00:00</td>\n      <td>And the glazier who fixed all the broken windo...</td>\n      <td>2701243</td>\n      <td>None</td>\n      <td>None</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5811403</td>\n      <td>99</td>\n      <td>99</td>\n      <td>1370234048</td>\n      <td>2013-06-03 04:34:08+00:00</td>\n      <td>Does canada have the equivalent of H1B/Green c...</td>\n      <td>5804452</td>\n      <td>None</td>\n      <td>None</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>21623</td>\n      <td>AF</td>\n      <td>AF</td>\n      <td>1178992400</td>\n      <td>2007-05-12 17:53:20+00:00</td>\n      <td>Speaking of Rails, there are other options in ...</td>\n      <td>21611</td>\n      <td>None</td>\n      <td>None</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10159727</td>\n      <td>EA</td>\n      <td>EA</td>\n      <td>1441206574</td>\n      <td>2015-09-02 15:09:34+00:00</td>\n      <td>Humans and large livestock (and maybe even pet...</td>\n      <td>10159396</td>\n      <td>None</td>\n      <td>None</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2988424</td>\n      <td>Iv</td>\n      <td>Iv</td>\n      <td>1315853580</td>\n      <td>2011-09-12 18:53:00+00:00</td>\n      <td>I must say I reacted in the same way when I re...</td>\n      <td>2988179</td>\n      <td>None</td>\n      <td>None</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"The `parent` column indicates the comment that was replied to and `id` is unique used to identify each comment","metadata":{}},{"cell_type":"code","source":"query_popular = \"\"\"SELECT parent, COUNT(id)\n                   FROM `bigquery-public-data.hacker_news.comments`\n                   GROUP BY parent\n                   HAVING COUNT(id)>10\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-07-10T19:55:58.457385Z","iopub.execute_input":"2021-07-10T19:55:58.457809Z","iopub.status.idle":"2021-07-10T19:55:58.462679Z","shell.execute_reply.started":"2021-07-10T19:55:58.457773Z","shell.execute_reply":"2021-07-10T19:55:58.461480Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"safe_config = bigquery.QueryJobConfig(maximum_bytes_billed = 10**10)\nquery_job = client.query(query_popular, job_config=safe_config)\n\npopular_comments = query_job.to_dataframe()\npopular_comments.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-10T19:56:01.367497Z","iopub.execute_input":"2021-07-10T19:56:01.367917Z","iopub.status.idle":"2021-07-10T19:56:08.462243Z","shell.execute_reply.started":"2021-07-10T19:56:01.367879Z","shell.execute_reply":"2021-07-10T19:56:08.460900Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/google/cloud/bigquery/client.py:440: UserWarning: Cannot create BigQuery Storage client, the dependency google-cloud-bigquery-storage is not installed.\n  \"Cannot create BigQuery Storage client, the dependency \"\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"    parent  f0_\n0  4684384   87\n1  6584683   47\n2  9616946   78\n3  7750036   57\n4  8185461   63","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>parent</th>\n      <th>f0_</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4684384</td>\n      <td>87</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6584683</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9616946</td>\n      <td>78</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7750036</td>\n      <td>57</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8185461</td>\n      <td>63</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"If you are ever unsure what to put inside the **COUNT()** function, you can do `COUNT(1)` to count the rows in each group. Most people find it especially readable, because we know it's not focusing on other columns. It also **scans less data** than if supplied column names (making it faster and using less of your data access quota).","metadata":{}},{"cell_type":"code","source":"query_improved = \"\"\"SELECT parent, COUNT(1) AS Num_Posts FROM `bigquery-public-data.hacker_news.comments`\n                    GROUP BY parent\n                    HAVING COUNT(1)>10\"\"\"\n\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed = 10**10)\n\nquery_job = client.query(query_improved,job_config = safe_config)\n\nimproved_df = query_job.to_dataframe()\nimproved_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-10T20:08:08.009327Z","iopub.execute_input":"2021-07-10T20:08:08.009986Z","iopub.status.idle":"2021-07-10T20:08:14.272826Z","shell.execute_reply.started":"2021-07-10T20:08:08.009932Z","shell.execute_reply":"2021-07-10T20:08:14.271645Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/google/cloud/bigquery/client.py:440: UserWarning: Cannot create BigQuery Storage client, the dependency google-cloud-bigquery-storage is not installed.\n  \"Cannot create BigQuery Storage client, the dependency \"\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"    parent  Num_Posts\n0  7536283         45\n1  4053076        242\n2  2530963         59\n3  1934367         70\n4  8204007         43","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>parent</th>\n      <th>Num_Posts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7536283</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4053076</td>\n      <td>242</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2530963</td>\n      <td>59</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1934367</td>\n      <td>70</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8204007</td>\n      <td>43</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Note that because it tells SQL how to apply aggregate functions (like COUNT()), it doesn't make sense to use GROUP BY without an aggregate function. Similarly, if you have any GROUP BY clause, then all variables must be passed to either a\n\nGROUP BY command, or\nan aggregation function.\n\n```\nquery_good = \"\"\"\n             SELECT parent, COUNT(id)\n             FROM `bigquery-public-data.hacker_news.comments`\n             GROUP BY parent\n             \"\"\"\n```\n\nNote that there are two variables: `parent` and `id`.\n\nparent was passed to a GROUP BY command (in `GROUP BY parent`), and\nid was passed to an aggregate function (in `COUNT(id)`).\n\nAnd this query won't work, because the `author` column isn't passed to an aggregate function or a GROUP BY clause:\n\n```\nquery_bad = \"\"\"\n            SELECT author, parent, COUNT(id)\n            FROM `bigquery-public-data.hacker_news.comments`\n            GROUP BY parent\n            \"\"\"\n```\n\n***If make this error, you'll get the error message SELECT list expression references column (column's name) which is neither grouped nor aggregated at.***","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}